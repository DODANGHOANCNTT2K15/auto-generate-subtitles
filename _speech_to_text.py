import whisper
import srt
from datetime import timedelta
from tqdm import tqdm
import os
import torch
from _normalize_audio import normalize_audio
from _reduce_noise import reduce_noise

language_map = {
    "en": "en",
    "ja": "ja",
}

def transcribe_with_whisper(audio_path, output_srt, language_code="en", model_size="base"):
    """Nháº­n diá»‡n giá»ng nÃ³i vÃ  táº¡o phá»¥ Ä‘á» SRT tá»« file Ã¢m thanh."""
    try:
        if not os.path.exists(audio_path):
            print(f"âŒ File Ã¢m thanh {audio_path} khÃ´ng tá»“n táº¡i.")
            return
        
        # Táº¡o tÃªn file táº¡m
        base_name = os.path.splitext(os.path.basename(audio_path))[0]
        normalized_path = f"temp_normalized_{base_name}.wav"
        denoised_path = f"temp_denoised_{base_name}.wav"

        # Tiá»n xá»­ lÃ½ Ã¢m thanh
        print("ğŸ”Š Tiá»n xá»­ lÃ½ Ã¢m thanh...")

        normalized_audio_path = normalize_audio(audio_path, normalized_path)
        if not normalized_audio_path:
            return

        denoised_audio_path = reduce_noise(normalized_audio_path, denoised_path)
        if not denoised_audio_path:
            return

        print("âœ… Tiá»n xá»­ lÃ½ hoÃ n táº¥t.")
        
        # Cáº¥u hÃ¬nh mÃ´ hÃ¬nh
        max_threads = os.cpu_count()
        torch.set_num_threads(max_threads)
        print(f"âš™ï¸ Äang sá»­ dá»¥ng {max_threads} luá»“ng CPU...")
        lang = language_map.get(language_code.lower(), "en")
        print(f"ğŸ§  Äang táº£i mÃ´ hÃ¬nh Whisper: {model_size}")
        model = whisper.load_model(model_size)

        # Nháº­n diá»‡n
        print(f"ğŸ”Š Äang nháº­n diá»‡n tá»«: {denoised_audio_path} ({lang})...")
        result = model.transcribe(
            denoised_audio_path,
            language=lang,
            verbose=False,
            temperature=0.6,
            beam_size=10,
            word_timestamps=True,
        )

        # Ghi phá»¥ Ä‘á»
        subtitles = []
        print("ğŸ“ Äang táº¡o phá»¥ Ä‘á» SRT...")
        for i, segment in tqdm(enumerate(result["segments"]), total=len(result["segments"]), desc="Táº¡o SRT"):
            start = timedelta(seconds=segment["start"])
            end = timedelta(seconds=segment["end"])
            text = segment["text"].strip()
            sub = srt.Subtitle(index=i + 1, start=start, end=end, content=text)
            subtitles.append(sub)
        with open(output_srt, "w", encoding="utf-8") as f:
            f.write(srt.compose(subtitles))
        print(f"âœ… ÄÃ£ lÆ°u file phá»¥ Ä‘á»: {output_srt}")
        
        # XÃ³a file táº¡m
        for temp_file in [normalized_audio_path, denoised_audio_path, audio_path]:
            if os.path.exists(temp_file):
                os.remove(temp_file)

    except Exception as e:
        print(f"âŒ Lá»—i khi xá»­ lÃ½: {str(e)}")
